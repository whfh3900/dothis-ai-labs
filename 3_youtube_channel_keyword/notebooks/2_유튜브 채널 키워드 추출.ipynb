{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유튜브 채널 키워드 추출\n",
    "\n",
    "이 프로젝트는 유튜브 채널의 텍스트 데이터를 정제한 후, **TF-IDF**(Term Frequency-Inverse Document Frequency) 기법을 적용하여 주요 키워드를 추출하는 과정을 설명합니다. 이 방법은 각 채널에서 빈번히 사용되지만 다른 채널에서는 상대적으로 드물게 나타나는 단어들을 중요 키워드로 선정합니다.\n",
    "\n",
    "추출된 키워드는 유입 사용자들이 채널의 핵심 주제를 빠르게 파악하는 데 도움을 주며, 콘텐츠 제작자에게는 새로운 콘텐츠 아이디어를 제공하는 데 활용됩니다.\n",
    "\n",
    "## 주요 단계:\n",
    "1. **데이터 정제**: 채널 설명 및 제목 등 텍스트 데이터를 수집하고 불필요한 요소 제거.\n",
    "2. **TF-IDF 계산**: 각 채널에서 사용된 단어들의 빈도를 기반으로 TF-IDF 값을 계산하여 중요 키워드 선정.\n",
    "3. **키워드 추출**: TF-IDF 값이 높은 단어들을 주요 키워드로 추출.\n",
    "4. **결과 활용**: 추출된 키워드를 바탕으로 채널의 핵심 주제를 정의하고, 콘텐츠 아이디어를 도출.\n",
    "\n",
    "이 과정은 채널의 특성을 명확히 이해하는 데 기여하며, 사용자와의 상호작용을 증대시키기 위한 전략 수립에도 도움이 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널 데이터와 비디오 데이터 불러오기\n",
    "channel_data = pd.read_csv(\"../data/channel_sample.csv\", encoding=\"utf-8-sig\", index_col=0)\n",
    "video_data = pd.read_csv(\"../data/video_sample_add_pre.csv\", encoding=\"utf-8-sig\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_published</th>\n",
       "      <th>video_category</th>\n",
       "      <th>video_info_card</th>\n",
       "      <th>video_with_ads</th>\n",
       "      <th>video_end_screen</th>\n",
       "      <th>video_cluster</th>\n",
       "      <th>crawled_date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>pre_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2y3SQ2v5IQk</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>[자막뉴스] 홍수에 떠내려가자 '박수' '알박기 염치' 오죽했으면..</td>\n",
       "      <td>#알박기 #캠핑 #sbs뉴스 #알박기 #텐트 #캠핑</td>\n",
       "      <td>[]</td>\n",
       "      <td>358</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>[ 자막뉴스 홍수에 떠내려가자 박수 알박기 염치  #알박기 #캠핑 #sbs뉴스 #알...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UMnnHdJHx-U</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>중국 일당에 \"다 들어와\"…공포에 떤 유흥가 (자막뉴스)</td>\n",
       "      <td>#범죄도시 #6000 #sbs뉴스 지난 2012년 한국으로 귀화한 중국 연변 출신의...</td>\n",
       "      <td>[]</td>\n",
       "      <td>354</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>중국 일당에 다 들어와 공포에 떤 유흥가 자막뉴스  #범죄도시 #6000 #sbs뉴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xLz-nqWD8lw</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>국힘당 문자 하나로 파장! 지지율 폭락 예정! 장철민, 청탁금지법? 권익위원장에게 ...</td>\n",
       "      <td>#노종면 #장철민 #sbs뉴스 #장철민 #인요한 #노종면</td>\n",
       "      <td>[]</td>\n",
       "      <td>584</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>국힘당 문자 하나로 파장 지지율 장철민 청탁금지법 권익위원장에게 물어보니 노종면의원...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UDjGTZi934E</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>한국 건물주 된 중국인 여대생...누리꾼 공분한 까닭</td>\n",
       "      <td>#오클릭 #SBS뉴스 #sbs뉴스 SNS를 통해 오늘(27일) 하루 관심사와 누리꾼...</td>\n",
       "      <td>[]</td>\n",
       "      <td>371</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>한국 건물주 된 중국인 여대생 누리꾼 공분한 까닭  #오클릭 #SBS뉴스 #sbs뉴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VTiODAvtK8A</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>강유정의원 질의도중 불순한태도 보이는 총무비서관!...오늘 처음으로 한마디하는 박찬...</td>\n",
       "      <td>#박찬대 #강유정 #sbs뉴스 #강유정 #박찬대 #총무비서관</td>\n",
       "      <td>[]</td>\n",
       "      <td>616</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>강유정의원 질의도중 불순한태도 보이는 총무비서관 처음으로 한마디하는 박찬대 박성준 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lOOJIrVUXP8</td>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "      <td>이곳에 갇혀 죽을 날만 기다립니다' 북한 내부 주민과의 비밀 인터뷰</td>\n",
       "      <td>#북한 #sbs뉴스 세 명의 북한 주민들은 BBC와의 독점 비밀 인터뷰를 통해 전 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>373</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2024-10-07 17:44:27</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>이곳에 죽을 북한 내부 주민과의 비밀 인터뷰  #북한 #sbs뉴스 [SEP] New...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                channel_id  \\\n",
       "0  2y3SQ2v5IQk  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "1  UMnnHdJHx-U  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "2  xLz-nqWD8lw  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "3  UDjGTZi934E  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "4  VTiODAvtK8A  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "5  lOOJIrVUXP8  UC3_oS5M6sufpC03eS2L8fPg   \n",
       "\n",
       "                                         video_title  \\\n",
       "0             [자막뉴스] 홍수에 떠내려가자 '박수' '알박기 염치' 오죽했으면..   \n",
       "1                    중국 일당에 \"다 들어와\"…공포에 떤 유흥가 (자막뉴스)   \n",
       "2  국힘당 문자 하나로 파장! 지지율 폭락 예정! 장철민, 청탁금지법? 권익위원장에게 ...   \n",
       "3                      한국 건물주 된 중국인 여대생...누리꾼 공분한 까닭   \n",
       "4  강유정의원 질의도중 불순한태도 보이는 총무비서관!...오늘 처음으로 한마디하는 박찬...   \n",
       "5              이곳에 갇혀 죽을 날만 기다립니다' 북한 내부 주민과의 비밀 인터뷰   \n",
       "\n",
       "                                   video_description video_tags  \\\n",
       "0                       #알박기 #캠핑 #sbs뉴스 #알박기 #텐트 #캠핑         []   \n",
       "1  #범죄도시 #6000 #sbs뉴스 지난 2012년 한국으로 귀화한 중국 연변 출신의...         []   \n",
       "2                    #노종면 #장철민 #sbs뉴스 #장철민 #인요한 #노종면         []   \n",
       "3  #오클릭 #SBS뉴스 #sbs뉴스 SNS를 통해 오늘(27일) 하루 관심사와 누리꾼...         []   \n",
       "4                  #박찬대 #강유정 #sbs뉴스 #강유정 #박찬대 #총무비서관         []   \n",
       "5  #북한 #sbs뉴스 세 명의 북한 주민들은 BBC와의 독점 비밀 인터뷰를 통해 전 ...         []   \n",
       "\n",
       "   video_duration video_published   video_category  video_info_card  \\\n",
       "0             358      2024-10-06  News & Politics                0   \n",
       "1             354      2024-10-06  News & Politics                0   \n",
       "2             584      2024-10-06  News & Politics                0   \n",
       "3             371      2024-10-06  News & Politics                0   \n",
       "4             616      2024-10-06  News & Politics                0   \n",
       "5             373      2024-10-06  News & Politics                0   \n",
       "\n",
       "   video_with_ads  video_end_screen  video_cluster         crawled_date  year  \\\n",
       "0               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "1               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "2               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "3               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "4               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "5               0                 0             -1  2024-10-07 17:44:27  2024   \n",
       "\n",
       "   month  day                                           pre_text  \n",
       "0     10    6  [ 자막뉴스 홍수에 떠내려가자 박수 알박기 염치  #알박기 #캠핑 #sbs뉴스 #알...  \n",
       "1     10    6  중국 일당에 다 들어와 공포에 떤 유흥가 자막뉴스  #범죄도시 #6000 #sbs뉴...  \n",
       "2     10    6  국힘당 문자 하나로 파장 지지율 장철민 청탁금지법 권익위원장에게 물어보니 노종면의원...  \n",
       "3     10    6  한국 건물주 된 중국인 여대생 누리꾼 공분한 까닭  #오클릭 #SBS뉴스 #sbs뉴...  \n",
       "4     10    6  강유정의원 질의도중 불순한태도 보이는 총무비서관 처음으로 한마디하는 박찬대 박성준 ...  \n",
       "5     10    6  이곳에 죽을 북한 내부 주민과의 비밀 인터뷰  #북한 #sbs뉴스 [SEP] New...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# channel_id가 5개 이상인 항목 즉, 영상을 5개 이상 업로드한 채널만 추출\n",
    "video_data = video_data.groupby('channel_id').filter(lambda x: len(x) >= 5).reset_index(drop=True)\n",
    "channel_data = channel_data[channel_data.CHANNEL_ID.isin(video_data.channel_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHANNEL_ID</th>\n",
       "      <td>UC3_oS5M6sufpC03eS2L8fPg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_NAME</th>\n",
       "      <td>간편이슈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_DESCRIPTION</th>\n",
       "      <td>간편이슈 채널입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_TAGS</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAINLY_USED_KEYWORDS</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAINLY_USED_TAGS</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_COUNTRY</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_LINK</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_SINCE</th>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_CLUSTER</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRAWLED_DATE</th>\n",
       "      <td>2024-10-09 17:00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_id_part</th>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_THUMBNAIL</th>\n",
       "      <td>https://yt3.googleusercontent.com/sZ0GuO7Ziw6D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0\n",
       "CHANNEL_ID                                     UC3_oS5M6sufpC03eS2L8fPg\n",
       "CHANNEL_NAME                                                       간편이슈\n",
       "CHANNEL_DESCRIPTION                                         간편이슈 채널입니다.\n",
       "CHANNEL_TAGS                                                         []\n",
       "MAINLY_USED_KEYWORDS                                                NaN\n",
       "MAINLY_USED_TAGS                                                    NaN\n",
       "CHANNEL_COUNTRY                                                     NaN\n",
       "CHANNEL_LINK                                                        NaN\n",
       "CHANNEL_SINCE                                                2017-03-17\n",
       "CHANNEL_CLUSTER                                                       9\n",
       "CRAWLED_DATE                                        2024-10-09 17:00:16\n",
       "USER_ID                                                             NaN\n",
       "channel_id_part                                                       _\n",
       "CHANNEL_THUMBNAIL     https://yt3.googleusercontent.com/sZ0GuO7Ziw6D..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영상이 5개 이상인 채널이 한 개뿐이므로 해당 채널만 분석\n",
    "channel_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "    def __init__(self, josa_path = \"../data/kor_josa.txt\", \n",
    "                 stopwords_path=\"../data/stopwords.txt\"):\n",
    "        \"\"\"\n",
    "        TextCleaner 클래스의 초기화 함수.\n",
    "        조사(Josa)와 불용어(Stopwords) 목록을 파일에서 읽어들여 리스트로 저장합니다.\n",
    "\n",
    "        Args:\n",
    "            josa_path (str): 조사 파일 경로\n",
    "            stopwords_path (str): 불용어 파일 경로\n",
    "        \"\"\"\n",
    "        \n",
    "        # 조사 리스트 초기화 및 파일에서 조사 데이터 로드\n",
    "        self.josa_list = set()\n",
    "        with open(josa_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            for line in f:\n",
    "                text = line.strip()\n",
    "                if text:\n",
    "                    self.josa_list.add(text)\n",
    "        self.josa_list = list(self.josa_list)  # 리스트 형태로 변환\n",
    "        \n",
    "        # 불용어 리스트 초기화 및 파일에서 불용어 데이터 로드\n",
    "        self.stopwords_list = set()\n",
    "        with open(stopwords_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            for line in f:\n",
    "                text = line.strip()\n",
    "                if text:\n",
    "                    self.stopwords_list.add(text)\n",
    "        self.stopwords_list = list(self.stopwords_list)  # 리스트 형태로 변환\n",
    "\n",
    "    def clean_and_filter_text(self, text):\n",
    "        \"\"\"\n",
    "        주어진 텍스트를 정리하고, 불용어 제거 및 조사 제거 작업을 수행하는 함수.\n",
    "\n",
    "        Args:\n",
    "            text (str): 처리할 텍스트\n",
    "\n",
    "        Returns:\n",
    "            str: 정리 및 필터링된 텍스트, 필터링에 걸리면 빈 문자열을 반환\n",
    "        \"\"\"\n",
    "        \n",
    "        # 텍스트 양쪽 공백 제거 및 특수문자 처리\n",
    "        text = text.strip()\n",
    "        text = self.clean_text(text)\n",
    "        \n",
    "        # 불용어 리스트에 포함되어 있으면 빈 문자열 반환\n",
    "        if text in self.stopwords_list:\n",
    "            return \"\"\n",
    "        \n",
    "        # 일련번호 패턴에 해당하면 빈 문자열 반환\n",
    "        if not self.filter_serial_pattern(text):\n",
    "            return \"\"\n",
    "\n",
    "        # 조사 제거 (텍스트가 조사로 끝날 경우 해당 부분을 제거)\n",
    "        for josa in self.josa_list:\n",
    "            # 조사 리스트에서 길이가 2 이상이거나 단일 조사(는, 를, 의, 에 등)에 해당하면 처리\n",
    "            if (text.endswith(josa)) and ((len(josa) >= 2) or (josa in ['는', '를', '의', '에', '와', '들'])):\n",
    "                return text[:-len(josa)]\n",
    "        \n",
    "        # 별도의 처리 필요 없는 경우 원본 텍스트 반환\n",
    "        return text\n",
    "\n",
    "    def clean_text(self, word):\n",
    "        \"\"\"\n",
    "        텍스트에서 일부 특수문자를 제거하고 불필요한 공백을 처리하는 함수.\n",
    "\n",
    "        Args:\n",
    "            word (str): 처리할 단어\n",
    "\n",
    "        Returns:\n",
    "            str: 특수문자 제거 및 공백 정리된 텍스트\n",
    "        \"\"\"\n",
    "        # 일부 특수문자를 공백으로 대체\n",
    "        for char in [\"`\", \"'\", \"#\", \",\", \"]\", \"[\"]:\n",
    "            word = word.replace(char, \" \")\n",
    "        \n",
    "        # 두 개 이상의 연속된 공백을 하나로 줄임, 양쪽 공백 제거\n",
    "        word = re.sub(r'\\s{2,}', ' ', word).strip()\n",
    "        \n",
    "        return word\n",
    "    \n",
    "    def filter_serial_pattern(self, word):\n",
    "        \"\"\"\n",
    "        특정 문자로 시작하고 숫자로 끝나는 일련번호 같은 단어를 제외하는 함수.\n",
    "\n",
    "        Args:\n",
    "            word (str): 검사할 단어\n",
    "\n",
    "        Returns:\n",
    "            bool: 조건에 맞으면 False, 그렇지 않으면 True\n",
    "        \"\"\"\n",
    "        # 정규표현식 패턴: 영문자나 한글로 시작하고, 숫자로 끝나는지 확인\n",
    "        pattern = r'^[가-힣a-zA-Z].*\\d$'\n",
    "        \n",
    "        # 조건에 맞으면 False 반환 (일련번호로 간주하여 제외), 맞지 않으면 True 반환\n",
    "        return not bool(re.match(pattern, word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordExtractor(TextCleaner):\n",
    "\n",
    "    def __init__(self, josa_path='./kor_josa.txt', stopwords_path=\"./stopwords_fin.txt\"):\n",
    "        \"\"\"\n",
    "        KeywordExtractor 초기화 메소드.\n",
    "        josa_path와 stopwords_path를 받아 조사와 불용어 리스트를 초기화합니다.\n",
    "\n",
    "        Args:\n",
    "            josa_path (str): 조사가 저장된 파일의 경로.\n",
    "            stopwords_path (str): 불용어가 저장된 파일의 경로.\n",
    "        \"\"\"\n",
    "        super().__init__(josa_path=josa_path, stopwords_path=stopwords_path)\n",
    "\n",
    "        # 불용어 리스트 초기화\n",
    "        self.stopwords = set()\n",
    "        with open(stopwords_path, \"rt\", encoding=\"utf-8-sig\") as f:\n",
    "            while True:\n",
    "                text = f.readline().strip()\n",
    "                if text:\n",
    "                    self.stopwords.add(text)  # 불용어 추가\n",
    "                if not text:\n",
    "                    break  # 파일의 끝에 도달하면 중단\n",
    "        self.stopwords = list(self.stopwords)  # 불용어를 리스트로 변환\n",
    "\n",
    "    def extract_keywords_from_tfidf(self, docs, threshold_1=0.8, threshold_2=3, ntop=30, keyword_max=None, use_upper=True):\n",
    "        \"\"\"\n",
    "        TF-IDF를 기반으로 문서에서 키워드를 추출하는 메소드.\n",
    "        \n",
    "        Args:\n",
    "            docs (list of str): 처리할 문서 리스트.\n",
    "            threshold_1 (float): 키워드 등장수 / 문서수의 임계값 (키워드 필터링 조건).\n",
    "            threshold_2 (int): 키워드 등장수의 임계값 (최소 등장 수).\n",
    "            ntop (int): 추출할 상위 키워드의 최대 개수.\n",
    "            keyword_max (int): 키워드의 최대 길이 (None일 경우 제한 없음).\n",
    "            use_upper (bool): 키워드를 대문자로 변환할지 여부.\n",
    "\n",
    "        Returns:\n",
    "            list: 추출된 키워드 리스트.\n",
    "        \"\"\"\n",
    "        # TF-IDF 벡터라이저 초기화\n",
    "        vector = TfidfVectorizer()\n",
    "\n",
    "        # TF-IDF 벡터 변환 시도\n",
    "        try:\n",
    "            tfidf = vector.fit_transform(docs).toarray()\n",
    "        except Exception as e:\n",
    "            return list()  # 오류 발생 시 빈 리스트 반환\n",
    "        \n",
    "        # 피처(키워드) 이름 추출\n",
    "        columns = vector.get_feature_names_out()\n",
    "\n",
    "        # TF-IDF 결과를 데이터프레임으로 변환\n",
    "        tfidf = pd.DataFrame(tfidf, columns=columns)\n",
    "\n",
    "        # 각 키워드가 등장한 문서 수로 변환 (0/1 값으로 변환 후 합산)\n",
    "        tfidf = tfidf.astype(bool).sum(axis=0)\n",
    "\n",
    "        # 숫자로만 이루어진 키워드는 제거\n",
    "        tfidf = tfidf[~tfidf.index.str.isdigit()]\n",
    "\n",
    "        # TF-IDF 가중치 합계\n",
    "        sum_score = sum(tfidf)\n",
    "\n",
    "        # 키워드의 상대적 가중치로 변환 (전체 합으로 나누기)\n",
    "        tfidf = tfidf / sum_score\n",
    "\n",
    "        # 키워드를 가중치에 따라 내림차순으로 정렬\n",
    "        tfidf = tfidf.sort_values(ascending=False)\n",
    "\n",
    "        # 불용어 제거\n",
    "        tfidf_result = [word for word in tfidf.index if word not in self.stopwords]\n",
    "        result = list()\n",
    "\n",
    "        # 키워드 필터링 및 추출\n",
    "        for keyword in tfidf_result:\n",
    "            if len(result) >= ntop:\n",
    "                break  # 상위 ntop 키워드만 추출\n",
    "            \n",
    "            keyword = keyword.strip()  # 키워드 앞뒤 공백 제거\n",
    "\n",
    "            # 키워드의 길이가 keyword_max보다 크면 패스\n",
    "            if keyword_max and len(keyword) > keyword_max:\n",
    "                continue\n",
    "            # 문서 내에서 해당 키워드의 등장 빈도 계산\n",
    "            count = sum(text.lower().split().count(keyword.lower()) for text in docs)\n",
    "            # 필터링 조건 적용: 문서 수 대비 등장 비율 및 최소 등장 수 기준\n",
    "            if (count / len(docs) <= threshold_1) and (count >= threshold_2):\n",
    "                # 조사 제거 등의 후처리 진행\n",
    "                keyword = self.clean_and_filter_text(keyword)\n",
    "                \n",
    "                if keyword and len(keyword) > 1:  # 빈 문자열이나 1글자 키워드는 제외\n",
    "                    if use_upper:  # 대문자로 변환\n",
    "                        keyword = keyword.upper()\n",
    "                    result.append(keyword)  # 결과에 추가\n",
    "\n",
    "        # 중복 키워드 제거한 리스트 반환\n",
    "        return list(OrderedDict.fromkeys(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEWS', 'POLITICS', '자막뉴스']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ke = KeywordExtractor(josa_path=\"../data/kor_josa.txt\",\n",
    "                 stopwords_path=\"../data/stopwords_for_keyword.txt\")\n",
    "ke.extract_keywords_from_tfidf(video_data.pre_text.tolist(),\n",
    "                               threshold_1=1.0, threshold_2=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
