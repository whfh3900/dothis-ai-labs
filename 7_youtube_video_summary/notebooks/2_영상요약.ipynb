{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RsVKZrt2DSo</td>\n",
       "      <td>대리모 사건이 소환한 합법화 논쟁 / KBC뉴스</td>\n",
       "      <td>리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CpgC1K7jNI</td>\n",
       "      <td>대포죽순이요????푸바오 핸펀몰카사건? 10.6 푸바오 이야기 FUBAO PANDA...</td>\n",
       "      <td>바 사님이 부르시는데 핸드폰으로 후버 찍어 주시는데 부바 부르는 목소리에 벌떡 일어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-jOF1sgdOg</td>\n",
       "      <td>일본에 남겨진 한국의 문화유산【아시아의 숨은 혼, 백제를 가다 Part 2】</td>\n",
       "      <td>고대 일본의 수도였던 오사가 동에 위치한 가시와라시 5세기 후반에 조성된 대형 무덤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giUtBrfvLJU</td>\n",
       "      <td>김동건변호사 고향사찰 구천면 정수사 다녀갑니다</td>\n",
       "      <td>넘게 있어요 이거 위가요 쭉 있는데 있는 바 예 그래고 그냥 이렇게 해라 너무 많이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8HRFrskGuks</td>\n",
       "      <td>\"롤드컵의 페이커는 다릅니다\" 고전파 모드 페이커 사일러스 등장 | 롤 하이라이트 ...</td>\n",
       "      <td>리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다 대회 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  RsVKZrt2DSo                         대리모 사건이 소환한 합법화 논쟁 / KBC뉴스   \n",
       "1  2CpgC1K7jNI  대포죽순이요????푸바오 핸펀몰카사건? 10.6 푸바오 이야기 FUBAO PANDA...   \n",
       "2  C-jOF1sgdOg         일본에 남겨진 한국의 문화유산【아시아의 숨은 혼, 백제를 가다 Part 2】   \n",
       "3  giUtBrfvLJU                          김동건변호사 고향사찰 구천면 정수사 다녀갑니다   \n",
       "4  8HRFrskGuks  \"롤드컵의 페이커는 다릅니다\" 고전파 모드 페이커 사일러스 등장 | 롤 하이라이트 ...   \n",
       "\n",
       "                                        video_script  \n",
       "0  리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...  \n",
       "1  바 사님이 부르시는데 핸드폰으로 후버 찍어 주시는데 부바 부르는 목소리에 벌떡 일어...  \n",
       "2  고대 일본의 수도였던 오사가 동에 위치한 가시와라시 5세기 후반에 조성된 대형 무덤...  \n",
       "3  넘게 있어요 이거 위가요 쭉 있는데 있는 바 예 그래고 그냥 이렇게 해라 너무 많이...  \n",
       "4  리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다 대회 이...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"../data/video_script.csv\", encoding=\"utf-8-sig\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # GPU 메모리 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kobert 모델 불러오기\n",
    "model_id = \"EbanLee/kobart-summary-v3\"\n",
    "cache_dir = \"../models\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_id, cache_dir=cache_dir)\n",
    "# GPU로 모델을 옮김\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]c:\\Users\\csu52\\anaconda3\\envs\\csu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 49/49 [04:34<00:00,  5.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_script</th>\n",
       "      <th>bert_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RsVKZrt2DSo</td>\n",
       "      <td>대리모 사건이 소환한 합법화 논쟁 / KBC뉴스</td>\n",
       "      <td>리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...</td>\n",
       "      <td>리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CpgC1K7jNI</td>\n",
       "      <td>대포죽순이요????푸바오 핸펀몰카사건? 10.6 푸바오 이야기 FUBAO PANDA...</td>\n",
       "      <td>바 사님이 부르시는데 핸드폰으로 후버 찍어 주시는데 부바 부르는 목소리에 벌떡 일어...</td>\n",
       "      <td>푸바오 먹을 죽순을 한 손 가득 가지고 나오셨네요 이렇게 많은 육수는 처음 보는 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-jOF1sgdOg</td>\n",
       "      <td>일본에 남겨진 한국의 문화유산【아시아의 숨은 혼, 백제를 가다 Part 2】</td>\n",
       "      <td>고대 일본의 수도였던 오사가 동에 위치한 가시와라시 5세기 후반에 조성된 대형 무덤...</td>\n",
       "      <td>야고는 고대일본 장 문화에도 변화를 가져옵니다. 먼저 무덤양식 수식에서 시신 주변을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giUtBrfvLJU</td>\n",
       "      <td>김동건변호사 고향사찰 구천면 정수사 다녀갑니다</td>\n",
       "      <td>넘게 있어요 이거 위가요 쭉 있는데 있는 바 예 그래고 그냥 이렇게 해라 너무 많이...</td>\n",
       "      <td>18세기 중 행다 화 구충은 기둥이 그대로 되어있고 시이 걸 그쪽에서 만나기로 했는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8HRFrskGuks</td>\n",
       "      <td>\"롤드컵의 페이커는 다릅니다\" 고전파 모드 페이커 사일러스 등장 | 롤 하이라이트 ...</td>\n",
       "      <td>리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다 대회 이...</td>\n",
       "      <td>리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다. 3면 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  RsVKZrt2DSo                         대리모 사건이 소환한 합법화 논쟁 / KBC뉴스   \n",
       "1  2CpgC1K7jNI  대포죽순이요????푸바오 핸펀몰카사건? 10.6 푸바오 이야기 FUBAO PANDA...   \n",
       "2  C-jOF1sgdOg         일본에 남겨진 한국의 문화유산【아시아의 숨은 혼, 백제를 가다 Part 2】   \n",
       "3  giUtBrfvLJU                          김동건변호사 고향사찰 구천면 정수사 다녀갑니다   \n",
       "4  8HRFrskGuks  \"롤드컵의 페이커는 다릅니다\" 고전파 모드 페이커 사일러스 등장 | 롤 하이라이트 ...   \n",
       "\n",
       "                                        video_script  \\\n",
       "0  리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...   \n",
       "1  바 사님이 부르시는데 핸드폰으로 후버 찍어 주시는데 부바 부르는 목소리에 벌떡 일어...   \n",
       "2  고대 일본의 수도였던 오사가 동에 위치한 가시와라시 5세기 후반에 조성된 대형 무덤...   \n",
       "3  넘게 있어요 이거 위가요 쭉 있는데 있는 바 예 그래고 그냥 이렇게 해라 너무 많이...   \n",
       "4  리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다 대회 이...   \n",
       "\n",
       "                                        bert_summary  \n",
       "0  리미나 난인 부부가 브로커에게 돈을 주고 출산을 의뢰한 대리모 범죄가 14년 만에 ...  \n",
       "1  푸바오 먹을 죽순을 한 손 가득 가지고 나오셨네요 이렇게 많은 육수는 처음 보는 거...  \n",
       "2  야고는 고대일본 장 문화에도 변화를 가져옵니다. 먼저 무덤양식 수식에서 시신 주변을...  \n",
       "3  18세기 중 행다 화 구충은 기둥이 그대로 되어있고 시이 걸 그쪽에서 만나기로 했는...  \n",
       "4  리시드 비지를 상대로 엄청난 활약을 보여준 페이커의 사일러스가 등장했습니다. 3면 ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bert_summary\"] = None\n",
    "\n",
    "# 각 스크립트에 대해 요약 생성\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    script = row[1].video_script\n",
    "    # 스크립트를 토크나이저를 통해 텐서로 변환, 패딩 및 잘림 처리\n",
    "    inputs = tokenizer(script, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=1026).to(device)\n",
    "    \n",
    "    # 요약 텍스트 ID 생성\n",
    "    summary_text_ids = model.generate(\n",
    "        input_ids=inputs['input_ids'],  # 입력 ID\n",
    "        attention_mask=inputs['attention_mask'],  # 주의 마스크\n",
    "        bos_token_id=model.config.bos_token_id,  # 시작 토큰 ID\n",
    "        eos_token_id=model.config.eos_token_id,  # 종료 토큰 ID\n",
    "        length_penalty=1.0,  # 길이에 대한 패널티 설정\n",
    "        max_length=512,  # 생성될 최대 길이\n",
    "        min_length=256,  # 생성될 최소 길이\n",
    "        num_beams=4,  # 빔 탐색의 수\n",
    "        repetition_penalty=2.0,  # 반복되는 단어에 대한 패널티\n",
    "        no_repeat_ngram_size=4,  # 반복되는 n-gram 크기\n",
    "        top_k=50,  # top-k 샘플링 설정\n",
    "        top_p=0.95  # top-p (nucleus) 샘플링 설정\n",
    "    )\n",
    "\n",
    "    # 생성된 요약 텍스트 ID를 디코딩하여 최종 요약 텍스트로 변환\n",
    "    bert_summary = tokenizer.decode(summary_text_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 생성된 요약을 데이터프레임에 저장\n",
    "    df.at[row[0], \"bert_summary\"] = bert_summary\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # GPU 메모리 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csu52\\anaconda3\\envs\\csu\\lib\\site-packages\\accelerate\\utils\\modeling.py:1390: UserWarning: Current model requires 4224 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 36.82it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama 모델 불러오기\n",
    "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "cache_dir = \"../models\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16, \"cache_dir\": cache_dir},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "pipeline.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 제목과 스크립트를 기반으로 유튜브 비디오의 내용을 설명하는 프롬프트입니다.\n",
    "# - 비디오가 무엇인지 설명합니다.\n",
    "# - 내용을 서론, 본론, 결론으로 나누어 한국어로 작성합니다.\n",
    "# - 스크립트에 포함되지 않은 내용은 요약에 포함하지 않습니다.\n",
    "PROMPT = '''\n",
    "            Based on the YouTube video title and script below, \n",
    "            please explain what video it is and provide it in Korean by dividing it into introduction, body, and conclusion. \n",
    "            Do not include anything that is not in the script in the summary.\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]c:\\Users\\csu52\\anaconda3\\envs\\csu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\csu52\\anaconda3\\envs\\csu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# llama_summary 열을 데이터프레임에 추가\n",
    "df['llama_summary'] = None\n",
    "\n",
    "# 데이터프레임의 각 행에 대해 반복\n",
    "for row in tqdm(df.iterrows(), total=len(df)):\n",
    "    video_title = row[1].video_title  # 비디오 제목 가져오기\n",
    "    bert_summary = row[1].bert_summary  # BERT 요약 가져오기\n",
    "    \n",
    "    # 시스템과 사용자 메시지 설정\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},  # 시스템 역할로 프롬프트 설정\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"title: {video_title}, script: {bert_summary}\"\"\"}\n",
    "    ]\n",
    "\n",
    "    # 프롬프트를 토크나이저를 통해 변환\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False,  # 토큰화 비활성화\n",
    "        add_generation_prompt=True  # 생성 프롬프트 추가\n",
    "    )\n",
    "\n",
    "    # 종료 토큰 ID 설정\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,  # EOS 토큰 ID\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  # 사용자 정의 종료 토큰 ID\n",
    "    ]\n",
    "\n",
    "    # Llama 모델을 통해 출력 생성\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=500,  # 생성할 텍스트 최대 길이 설정\n",
    "        eos_token_id=terminators,  # 종료 토큰 설정\n",
    "        do_sample=False,  # 무작위성 제거\n",
    "        temperature=0.4,  # 생성 시 창의성 감소\n",
    "        top_p=0.8,  # 선택할 확률 분포 제한\n",
    "        repetition_penalty=1.3  # 반복 방지 강화\n",
    "    )\n",
    "\n",
    "    # 생성된 요약을 데이터프레임에 저장\n",
    "    df.at[row[0], 'llama_summary'] = outputs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과저장\n",
    "df.to_csv(\"../data/video_summary.csv\", encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
