{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩 기반의 연관어 추출\n",
    "\n",
    "이 노트북에서는 전처리된 YouTube 데이터를 활용하여 **Word2Vec** 기반으로 연관어를 추출하는 과정을 설명합니다. \n",
    "\n",
    "데이터는 사전에 수집 및 전처리된 유튜브 비디오 메타 데이터를 사용하며, 주로 비디오 조회수와 키워드를 중심으로 분석을 진행합니다. **Word2Vec** 모델은 해당 키워드들의 의미적 유사성을 학습하여 연관된 단어들을 벡터 공간에서 가까운 위치에 배치합니다. 이를 통해 특정 키워드에 대한 연관어를 효과적으로 추출하고자 합니다.\n",
    "\n",
    "## 주요 단계:\n",
    "1. **데이터 로드**: 수집된 유튜브 데이터의 정제 및 전처리된 데이터 불러오기.\n",
    "2. **Word2Vec 학습**: 전처리된 텍스트 데이터를 바탕으로 임베딩 벡터 학습.\n",
    "3. **연관어 추출**: 학습된 모델을 활용하여 특정 키워드에 대한 유사도 높은 연관어 목록 도출.\n",
    "4. **결과 분석**: 추출된 연관어의 의미적 유사성 및 활용 가능성 검토."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로드\n",
    "df = pd.read_csv(\"../data/video_sample_20241013.csv\", encoding=\"utf-8-sig\", index_col=0)\n",
    "df.use_text = df.use_text.apply(lambda x: [word.strip() for word in x.split(\",\")])\n",
    "train_data = df.use_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "vector_size = 200\n",
    "min_count = 5\n",
    "window = 3\n",
    "workers = 18\n",
    "epochs = 1000\n",
    "epoch_increment = 100\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.0\n",
      "Epoch: 200, Loss: 0.0\n",
      "Epoch: 300, Loss: 0.0\n",
      "Epoch: 400, Loss: 0.0\n",
      "Epoch: 500, Loss: 0.0\n",
      "Epoch: 600, Loss: 0.0\n",
      "Early stopping: No improvement in loss for 5 consecutive epochs.\n"
     ]
    }
   ],
   "source": [
    "# 학습 관련 변수 초기화\n",
    "previous_losses = []  # 각 epoch에서 손실값을 저장할 리스트\n",
    "patience_counter = 0  # 개선이 없는 epoch 횟수를 추적하는 카운터\n",
    "best_loss = np.inf  # 현재까지의 최소 손실값을 저장 (초기값은 무한대)\n",
    "\n",
    "# Word2Vec 모델 초기화\n",
    "model = Word2Vec(train_data, vector_size=vector_size, \n",
    "                window=window, min_count=min_count, \n",
    "                workers=workers, sg=0, compute_loss=True)  # sg=0은 CBOW, compute_loss=True로 손실값 계산 활성화\n",
    "\n",
    "# 점진적 학습 루프\n",
    "for epoch in range(0, epochs, epoch_increment):  # 주어진 epoch 범위에서 epoch_increment 단위로 학습 진행\n",
    "    model.train(train_data, total_examples=model.corpus_count, epochs=epoch_increment)  # Word2Vec 모델 학습\n",
    "    current_loss = model.get_latest_training_loss()  # 현재 학습 손실값을 가져옴\n",
    "\n",
    "    # 손실값 평가\n",
    "    if current_loss < best_loss:  # 이전 최저 손실값보다 현재 손실값이 더 작으면\n",
    "        best_loss = current_loss  # 최저 손실값 갱신\n",
    "        patience_counter = 0  # 손실값이 개선되었으므로 카운터 초기화\n",
    "    else:\n",
    "        patience_counter += 1  # 손실값이 개선되지 않으면 카운터 증가\n",
    "\n",
    "    # 손실값을 저장하고 확인\n",
    "    previous_losses.append(current_loss)  # 현재 손실값을 리스트에 저장\n",
    "    print(f\"Epoch: {epoch + epoch_increment}, Loss: {current_loss}\")  # 현재 epoch과 손실값 출력\n",
    "\n",
    "    # 연속 5번 손실값이 줄어들지 않으면 학습 중단\n",
    "    if patience_counter >= patience:  # 설정된 patience 값(여기선 5) 이상 개선되지 않으면 조기 종료\n",
    "        print(\"Early stopping: No improvement in loss for 5 consecutive epochs.\")  # 조기 종료 메시지 출력\n",
    "        break  # 학습 종료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "cache_path = \"../models\"\n",
    "filepath = os.path.join(cache_path, \"related_model.bin\")\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김민재', 0.5350412130355835),\n",
       " ('레길론', 0.5053242444992065),\n",
       " ('아드리아누', 0.5034506320953369),\n",
       " ('피를로', 0.48978903889656067),\n",
       " ('황의조', 0.4843679368495941),\n",
       " ('손흥민', 0.4828548729419708),\n",
       " ('손홍민', 0.4817011058330536),\n",
       " ('세자르', 0.4740636646747589),\n",
       " ('조규성', 0.4608883261680603),\n",
       " ('축구대표팀', 0.45687970519065857)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연관어 추출\n",
    "keyword = \"이강인\"\n",
    "model.wv.similar_by_word(keyword)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
