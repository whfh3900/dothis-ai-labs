{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유튜브 조회수 기반 연관 단어 추출\n",
    "\n",
    "이 코드는 **유튜브 조회수**를 기준으로 특정 검색어와 연관된 단어를 추출하는 과정을 보여줍니다.\n",
    "\n",
    "## 과정 개요\n",
    "1. **데이터 필터링**: 입력된 검색어가 포함된 유튜브 데이터 프레임을 필터링합니다.\n",
    "2. **단어 빈도 분석**: 필터링된 데이터 내에서 각 단어의 빈도를 세고, 내림차순으로 정렬합니다.\n",
    "3. **조회수 기반 가중치 부여**: 각 단어의 조회수를 합산하여 연관 단어에 대한 가중치를 부여합니다.\n",
    "4. **최종 결과 도출**: 조회수가 높은 단어들을 연관 단어로 출력하여, 유의미한 연관성을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 데이터 불러오기\n",
    "# use_text 컬럼은 이전에 전처리를 끝낸 컬럼\n",
    "df = pd.read_csv(\"../data/video_sample_20241013.csv\", encoding=\"utf-8-sig\", index_col=0)\n",
    "df[\"use_text\"] = df[\"use_text\"].apply(lambda x: [word.strip() for word in x.split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 단어 정의\n",
    "target_word = \"먹방\"\n",
    "\n",
    "# 'use_text' 열에서 target_word가 포함된 행만 필터링\n",
    "filtered_df = df[df['use_text'].apply(lambda x: target_word in x)]\n",
    "\n",
    "# 필터링된 데이터에서 'use_text' 열의 리스트를 풀어서 모든 단어를 하나의 리스트로 만듭니다.\n",
    "all_words = [word for words_list in filtered_df['use_text'] for word in words_list]\n",
    "\n",
    "# 각 단어의 개수를 세어 Counter 객체 생성\n",
    "word_count = Counter(all_words)\n",
    "\n",
    "# target_word를 제외하고 나머지 단어들의 개수를 세어 딕셔너리 형태로 변환\n",
    "sorted_word_count = {word: count for word, count in word_count.items() if word != target_word}\n",
    "\n",
    "# 단어의 빈도를 기준으로 내림차순으로 정렬\n",
    "sorted_word_count = dict(sorted(sorted_word_count.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'korea': 2609411,\n",
       " 'life': 2585560,\n",
       " '차쥐뿔': 2491825,\n",
       " '지수': 2392946,\n",
       " '제니': 2381596,\n",
       " '마크': 2379054,\n",
       " 'SUB': 2379041,\n",
       " 'flower': 2378048,\n",
       " '이영지': 2377593,\n",
       " '도경수': 2377593}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 저장할 딕셔너리 초기화\n",
    "result = dict()\n",
    "\n",
    "# sorted_word_count에서 각 단어와 빈도를 반복\n",
    "for i, (key, value) in enumerate(sorted_word_count.items()):\n",
    "    # 해당 단어가 포함된 행을 필터링하여 새로운 DataFrame 생성\n",
    "    _df = filtered_df[filtered_df['use_text'].apply(lambda x: key in x)]\n",
    "    \n",
    "    # 필터링된 DataFrame에서 비디오 조회수를 합산\n",
    "    video_views_sum = _df[\"video_views\"].sum()\n",
    "    \n",
    "    # 조회수 합계를 정수로 변환\n",
    "    score = int(video_views_sum)\n",
    "    \n",
    "    # score가 NaN이 아닐 경우에만 결과에 추가\n",
    "    if not np.isnan(score):\n",
    "        result[key] = score\n",
    "\n",
    "# 조회수를 기준으로 내림차순 정렬\n",
    "result = dict(sorted(result.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# 결과에서 상위 10개 항목만 선택\n",
    "top_10_result = dict(list(result.items())[:10])\n",
    "\n",
    "# 상위 10개 결과 출력\n",
    "top_10_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
